{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the `score` assigned with each text amazon fine food reviews using xgboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\dena1\\anaconda3\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\dena1\\anaconda3\\lib\\site-packages (from wordcloud) (1.15.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\dena1\\anaconda3\\lib\\site-packages (from wordcloud) (5.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\dena1\\anaconda3\\lib\\site-packages (0.80)\n",
      "Requirement already satisfied: scipy in c:\\users\\dena1\\anaconda3\\lib\\site-packages (from xgboost) (1.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dena1\\anaconda3\\lib\\site-packages (from xgboost) (1.15.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dena1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dena1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install wordcloud\n",
    "!{sys.executable} -m pip install xgboost\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # colorful plots\n",
    "from collections import Counter\n",
    "import xgboost as xgb\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score #evaluation\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from time import time #check runtime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (50, 4)\n",
      "   Id  Score                                               Text  Positivity\n",
      "0   1      5  I have bought several of the Vitality canned d...           1\n",
      "1   2      1  Product arrived labeled as Jumbo Salted Peanut...           0\n",
      "2   3      4  This is a confection that has been around a fe...           1\n",
      "3   4      2  If you are looking for the secret ingredient i...           0\n",
      "4   5      5  Great taffy at a great price.  There was a wid...           1\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# Constants and Configurations\n",
    "\n",
    "DATA_LOCAL = True\n",
    "LOCAL_PATH = \"../data/\"\n",
    "REMOTE_PATH = \"https://s3.amazonaws.com/coetichr/AmazonFoodReviews/\"\n",
    "NROWS = 10000 #edit with a smaller size to develop faster\n",
    "TOKENIZER = RegexpTokenizer(r'\\w+') #no punctuation\n",
    "STEMMER = nltk.PorterStemmer()\n",
    "STOPWORD_CORPUS = stopwords.words(\"english\")\n",
    "sns.set(style=\"whitegrid\", context=\"paper\") #looks nicer with a blank background\n",
    "\n",
    "# TODO: Seperate this into a seperate file/ library so we can load it into all the scripts\n",
    "def load_data(file):\n",
    "    path = LOCAL_PATH if DATA_LOCAL else REMOTE_PATH\n",
    "    return pd.read_csv(path + file, nrows=NROWS)\n",
    "\n",
    "\n",
    "# Load Reviews.csv\n",
    "reviewsdf = load_data(\"Reviews.csv\")\n",
    "\n",
    "#drop columns not needed\n",
    "reviewsdf.drop(columns=[\"ProductId\", \"UserId\", \"ProfileName\", \"Time\", \"Summary\", \"HelpfulnessDenominator\", \"HelpfulnessNumerator\"], inplace=True, axis=1)\n",
    "reviewsdf.dropna(inplace=True) #drop empty fields\n",
    "reviewsdf['Positivity'] = np.where(reviewsdf['Score'] > 3, 1, 0)\n",
    "\n",
    "print(\"Shape: \", reviewsdf.shape)\n",
    "print(reviewsdf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "Look at the distribution of different scores and words received for each text review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "class QuickPlot:\n",
    "    def __init__(self, title=\"\"):\n",
    "        self.title = title;\n",
    "        \n",
    "    # df is a hash with word:freq mappings\n",
    "    def wordcloud(self, df):\n",
    "        wordcloud = WordCloud(\n",
    "            width=1400,\n",
    "            height=600,\n",
    "            background_color=\"white\",\n",
    "            colormap=\"Dark2\",\n",
    "            max_words=50,\n",
    "            mode=\"RGBA\").generate_from_frequencies(df)\n",
    "        # make figure to plot\n",
    "        plt.figure( figsize=(10,5))\n",
    "        # plot words\n",
    "        plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "        # remove axes\n",
    "        plt.axis(\"off\")\n",
    "        # show the result\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_confusion_matrix(xtest, ytest, preds):\n",
    "        cm = confusion_matrix(ytest, preds)\n",
    "        score = model.score(xtest, ytest)\n",
    "        plt.figure(figsize = (9,9))\n",
    "        sns.heatmap(cm, annot = True, fmt = \".3f\", linewidths = .5, square = True, cmap = 'Blues_r')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        title = 'Accuracy Score: {0}'.format(score)\n",
    "        plt.title(title, size = 15)\n",
    "        plt.show()\n",
    "        \n",
    "    def barplot(self, df):\n",
    "        plt.subplots(figsize = (15,10))\n",
    "        sns.barplot(x = df['count'], y = df['token'], palette = \"deep\").set_title(self.title)\n",
    "        plt.show() \n",
    "        \n",
    "    def countplot(self, df, xcol):\n",
    "        sns.countplot(x=xcol, data=df, palette=\"GnBu_d\").set_title(self.title)\n",
    "        plt.show()\n",
    "        \n",
    "#view distribution of scores\n",
    "plt.subplots(figsize=(10,5))\n",
    "QuickPlot(\"Score Distribution\").countplot(reviewsdf, \"Score\")\n",
    "\n",
    "#view top words for each score\n",
    "#sum_words = bow.sum(axis=0) \n",
    "#words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "#words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "#word_freq_dict = {}\n",
    "#for a, b in words_freq: \n",
    "#    word_freq_dict[a] = float(b)\n",
    "#QuickPlot().wordcloud(word_freq_dict)\n",
    "\n",
    "#words_freq_df = pd.DataFrame(word_freq_dict.items(),index=word_freq_dict.keys(), columns=[\"token\", \"count\"])\n",
    "#QuickPlot(\"Top 25 words in reviews\").barplot(words_freq_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Going to tokenize the words and anything that might need to be removed (stopwords, puncutation, etc), apply stemming where the root of the word is extracted from the sentence, and create a bag of words model. BoW representation specifies the occurrence of tokens in the whole corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 69\n",
      "X_train shape:  (185, 69)\n",
      "Y_train shape:  (65, 69)\n",
      "   I  I have  It  McCann  McCann s  My  Oatmeal  The  This  Twizzlers ...   \\\n",
      "0  1     NaN   0       0       NaN   0        0    0     0          0 ...    \n",
      "1  1     NaN   0       0       NaN   0        0    1     0          0 ...    \n",
      "2  2     NaN   0       0       NaN   0        0    0     0          0 ...    \n",
      "3  1     NaN   1       3       NaN   0        0    2     2          0 ...    \n",
      "4  1     NaN   1       0       NaN   0        0    3     1          0 ...    \n",
      "\n",
      "   this  to  too  up  very  was  we  will  with  you  \n",
      "0     1   4    0   0     0    1   0     0     1    2  \n",
      "1     2   1    0   1     0    0   0     0     0    0  \n",
      "2     1   1    0   1     0    0   5     1     1    4  \n",
      "3     1   8    0   3     0    0   0     0     3    9  \n",
      "4     3   1    1   0     1    0   0     0     3    1  \n",
      "\n",
      "[5 rows x 69 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dena1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "C:\\Users\\dena1\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parse the text into tokens and apply to the table, along with stemming\n",
    "def tokenizefn(row):\n",
    "    rownew = TOKENIZER.tokenize(row) #tokenize    \n",
    "    #stem\n",
    "    #rownew = list(map(lambda str: STEMMER.stem(str), rownew))\n",
    "    return rownew\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(reviewsdf[\"Text\"], reviewsdf['Positivity'], random_state = 0)\n",
    "\n",
    "X_train_full = None\n",
    "X_test_full = None\n",
    "\n",
    "#build BoW with different nfram ranges\n",
    "for irange in range(1,6):\n",
    "    vectorizer = CountVectorizer(\n",
    "    ngram_range = (1, irange),\n",
    "    analyzer = 'word',\n",
    "    tokenizer=tokenizefn,\n",
    "    lowercase=False,\n",
    "    min_df=5\n",
    "    ).fit(X_train)\n",
    "    \n",
    "    if irange <= 1:\n",
    "        X_train_full = pd.DataFrame(vectorizer.transform(X_train).toarray(), columns=vectorizer.get_feature_names())\n",
    "        X_test_full = pd.DataFrame(vectorizer.transform(X_test).toarray(), columns=vectorizer.get_feature_names())\n",
    "    else:       \n",
    "        X_train_full = pd.concat([X_train_full,pd.DataFrame(vectorizer.transform(X_train).toarray(), columns=vectorizer.get_feature_names()) ])\n",
    "        X_test_full = pd.concat([X_test_full,pd.DataFrame(vectorizer.transform(X_test).toarray(), columns=vectorizer.get_feature_names()) ])\n",
    "\n",
    "print(\"Number of features: \" + str(len(vectorizer.get_feature_names())))\n",
    "print('X_train shape: ', X_train_full.shape)\n",
    "print('Y_train shape: ', X_test_full.shape)\n",
    "print(X_test_full.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================\n",
      "Testing LogisticRegression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ee700f837199>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ovr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         n_jobs=-1))\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m '''\n",
      "\u001b[1;32m<ipython-input-19-ee700f837199>\u001b[0m in \u001b[0;36mtest_classifier\u001b[1;34m(X_train, y_train, X_test, y_test, classifier)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlist_of_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Learing time {0}s\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mnow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[1;32m-> 1220\u001b[1;33m                          order=\"C\")\n\u001b[0m\u001b[0;32m   1221\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "\n",
    "def test_classifier(X_train, y_train, X_test, y_test, classifier):\n",
    "    print(\"\")\n",
    "    print(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    print(\"Testing \" + classifier_name)\n",
    "    now = time()\n",
    "    list_of_labels = sorted(list(set(y_train)))\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    print(\"Learing time {0}s\".format(time() - now))\n",
    "    now = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"Predicting time {0}s\".format(time() - now))\n",
    "\n",
    "    precision = precision_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    recall = recall_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    print(\"=================== Results ===================\")\n",
    "    print(\"            Negative     Neutral     Positive\")\n",
    "    print(\"F1       \" + str(f1))\n",
    "    print(\"Precision\" + str(precision))\n",
    "    print(\"Recall   \" + str(recall))\n",
    "    print(\"Accuracy \" + str(accuracy))\n",
    "    print(\"===============================================\")\n",
    "\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "test_classifier(\n",
    "    X_train_full,\n",
    "    Y_train,\n",
    "    X_test_full,\n",
    "    Y_test,\n",
    "    LogisticRegression(\n",
    "        random_state=0,\n",
    "        solver='liblinear',\n",
    "        multi_class='ovr',\n",
    "        n_jobs=-1))\n",
    "\n",
    "'''\n",
    "test_classifier(\n",
    "    vectorizer.transform(X_train),\n",
    "    Y_train,\n",
    "    vectorizer.transform(X_test),\n",
    "    Y_test,\n",
    "    xgb.XGBClassifier(\n",
    "        silent=True,\n",
    "        max_depth=100,\n",
    "        n_jobs=4,\n",
    "        n_estimators=1000\n",
    "    ))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
